---
layout: page
title: Project Statement
permalink: /project_statement

---


## Background
Most Americans are exposed to a daily dose of false or misleading content — hoaxes, conspiracy theories, fabricated reports, click-bait headlines, and even satire. Such content is collectively referred to as “misinformation". There have been verified instances of misinformation and disinformation spreading on social media inflicting real harm on society, such as dangerous health decisions and stock market manipulations to name a few [[1]](https://arxiv.org/abs/1707.07592). Such events has led world leaders to identify the massive spread of digital misinformation as [a major global risk](http://reports.weforum.org/global-risks-2013/risk-case-1/digital-wildfires-in-a-hyperconnected-world/?doing_wp_cron=1533730169.0472350120544433593750). The impact of online misinformation spreading through the mechanism of malicious bots might be prevented if the activities of such bots are identified quickly and accurately [[1]](https://arxiv.org/abs/1707.07592).

## Project Statement

The aim of this project is to evaluate classification models that analyze tweets data using machine learning techniques to classify authors as human or bot. Some of the classifcation models we incorporate in this project include natural language processing techniques.

This project is consists of three high-level sections.
<ol>
<li>Data Collection</li>
<li>Data Processing</li>
<li>Modeling</li>
</ol>

In each section, you will find a description of the methodology employed in that section, a complete set of python codes used in that section, issues encountered (if any) and how they were handled, and remarks on noteworthy findings.

## Website Structure

<font color='red'>--> Include afterwards</font>
